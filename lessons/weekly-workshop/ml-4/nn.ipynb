{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets\n",
    "Let's start coding our neural net!\n",
    "\n",
    "### Data\n",
    "\n",
    "The first thing we need to do is load the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "#load the digits\n",
    "digits = load_digits()\n",
    "images = digits['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know what this dataset is all about before we can mess with it. Let's print it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "When we look at the images data, we see the images are encoded as a 2D matrix of pixel darkness, on a scale from 0 to 16. \n",
    "\n",
    "We need to reshape the data into a means our algorithm can read (1D!). Luckily sk learn has got a simple solution for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images) #we need to know the size of the data\n",
    "data1D = digits.images.reshape((n_samples, -1)) #so we can turn it from 2D to 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train and test__\n",
    "\n",
    "Like we saw with every other algorithm, we need to split our data into two parts: one to train, and another to test. SK learn makes that really easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_image, test_image, train_target, test_target = \\\n",
    "    train_test_split(data1D, digits['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier time!\n",
    "\n",
    "The neural net classifier we will choose from sklearn is the MLPClassifier, that is multi-layer perception (not my little pony). \n",
    "\n",
    "As with all ML algorithms we've seen, the devil is in choosing the perfect parameters. When making a ANN classifier, we want to start with one hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#how to even use MLPClassifier? just ask!\n",
    "MLPClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How would we make a mlp with 2 layers of 16 nodes each?\n",
    "mlp = MLPClassifier?\n",
    "#And how do we train this mlp?\n",
    "mlp.fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and evaluating our classifier\n",
    "\n",
    "Now let's run the classifier on the test set we made when we did the train-test split at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now of course sk learn has some easy prewritten functions to build a classification report. Isn't it great?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_target,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to draw a number in the grid!\n",
    "\n",
    "In the grid below you can \"draw\" a number by using values between 0 and 16. Zero would be \"nothing here\" and 16 would be \"very very dark here\". Does the neural network struggle with your \"artificial\" numbers? Does it struggle with certain numbers more than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mynumber = np.array([\n",
    "    0, 0, 0, 0, 5, 5, 0, 0, \n",
    "    0, 0, 12, 11, 11, 16, 0, 0, \n",
    "    0, 0, 15, 0, 0, 14, 0, 0, \n",
    "    0, 0, 12, 3, 0, 12, 0, 0, \n",
    "    0, 0, 7, 11, 11, 13, 0, 0, \n",
    "    0, 0, 0, 0, 0, 11, 0, 0, \n",
    "    0, 0, 0, 0, 0, 11, 0, 0, \n",
    "    0, 0, 0, 0, 0, 10, 0, 0,\n",
    "])\n",
    "mlp.predict([mynumber])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
